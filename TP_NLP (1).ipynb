{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des librairies \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "from sklearn import svm  \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "#from wordcloud import WordCloud, STOPWORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1      advice Talk to your neighbours family to excha...            Positive  \n",
       "2      Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3      My food stock is not the only one which is emp...            Positive  \n",
       "4      Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  Airline pilots offering to stock supermarket s...             Neutral  \n",
       "41153  Response to complaint not provided citing COVI...  Extremely Negative  \n",
       "41154  You know itÂs getting tough when @KameronWild...            Positive  \n",
       "41155  Is it wrong that the smell of hand sanitizer i...             Neutral  \n",
       "41156  @TartiiCat Well new/used Rift S are going for ...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lecture de du dataset et dans ce tp nous allons utiliser celui de l'analyse des sentiments \n",
    "dataset = pd.read_csv(\"data.csv\",encoding= \"ISO-8859-1\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive              11422\n",
       "Negative               9917\n",
       "Neutral                7713\n",
       "Extremely Positive     6624\n",
       "Extremely Negative     5481\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reponse à la question numéro1 du TP\n",
    "dataset['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##PRETRAITEMENT ET SUITE DES REPONSES AUX QUESTIONS POSEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>MeNyrbie  Phil Gahan  Chrisitv   and   and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Coronavirus Australia  Woolworths to give elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>Me  ready to go at supermarket during the  COV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>You know it  s getting tough when  KameronWild...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>TartiiCat Well new used Rift S are going for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \\\n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1      advice Talk to your neighbours family to excha...            Positive   \n",
       "2      Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3      My food stock is not the only one which is emp...            Positive   \n",
       "4      Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "...                                                  ...                 ...   \n",
       "41152  Airline pilots offering to stock supermarket s...             Neutral   \n",
       "41153  Response to complaint not provided citing COVI...  Extremely Negative   \n",
       "41154  You know itÂs getting tough when @KameronWild...            Positive   \n",
       "41155  Is it wrong that the smell of hand sanitizer i...             Neutral   \n",
       "41156  @TartiiCat Well new/used Rift S are going for ...            Negative   \n",
       "\n",
       "                                             clean_tweet  \n",
       "0           MeNyrbie  Phil Gahan  Chrisitv   and   and    \n",
       "1      advice Talk to your neighbours family to excha...  \n",
       "2      Coronavirus Australia  Woolworths to give elde...  \n",
       "3      My food stock is not the only one which is emp...  \n",
       "4      Me  ready to go at supermarket during the  COV...  \n",
       "...                                                  ...  \n",
       "41152  Airline pilots offering to stock supermarket s...  \n",
       "41153  Response to complaint not provided citing COVI...  \n",
       "41154  You know it  s getting tough when  KameronWild...  \n",
       "41155  Is it wrong that the smell of hand sanitizer i...  \n",
       "41156   TartiiCat Well new used Rift S are going for ...  \n",
       "\n",
       "[41157 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertir tout ce qui n'est pas a-z, A-Z, 0-9 en espace et supprimer le lien des tweets\n",
    "#Cette pratique est relative à la question numéro 2 du TP \n",
    "dataset['clean_tweet'] = dataset['OriginalTweet'].apply(lambda x: re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \", x))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>MeNyrbie  Phil Gahan  Chrisitv   and   and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Coronavirus Australia  Woolworths to give elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>Me  ready to go at supermarket during the  COV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1  advice Talk to your neighbours family to excha...            Positive   \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3  My food stock is not the only one which is emp...            Positive   \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0       MeNyrbie  Phil Gahan  Chrisitv   and   and    \n",
       "1  advice Talk to your neighbours family to excha...  \n",
       "2  Coronavirus Australia  Woolworths to give elde...  \n",
       "3  My food stock is not the only one which is emp...  \n",
       "4  Me  ready to go at supermarket during the  COV...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>MeNyrbie  Phil Gahan  Chrisitv   and   and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Coronavirus Australia  Woolworths to give elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Me  ready to go at supermarket during the  COV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>You know it  s getting tough when  KameronWild...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>TartiiCat Well new used Rift S are going for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           OriginalTweet  \\\n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n",
       "1      advice Talk to your neighbours family to excha...   \n",
       "2      Coronavirus Australia: Woolworths to give elde...   \n",
       "3      My food stock is not the only one which is emp...   \n",
       "4      Me, ready to go at supermarket during the #COV...   \n",
       "...                                                  ...   \n",
       "41152  Airline pilots offering to stock supermarket s...   \n",
       "41153  Response to complaint not provided citing COVI...   \n",
       "41154  You know itÂs getting tough when @KameronWild...   \n",
       "41155  Is it wrong that the smell of hand sanitizer i...   \n",
       "41156  @TartiiCat Well new/used Rift S are going for ...   \n",
       "\n",
       "                                             clean_tweet  \n",
       "0           MeNyrbie  Phil Gahan  Chrisitv   and   and    \n",
       "1      advice Talk to your neighbours family to excha...  \n",
       "2      Coronavirus Australia  Woolworths to give elde...  \n",
       "3      My food stock is not the only one which is emp...  \n",
       "4      Me  ready to go at supermarket during the  COV...  \n",
       "...                                                  ...  \n",
       "41152  Airline pilots offering to stock supermarket s...  \n",
       "41153  Response to complaint not provided citing COVI...  \n",
       "41154  You know it  s getting tough when  KameronWild...  \n",
       "41155  Is it wrong that the smell of hand sanitizer i...  \n",
       "41156   TartiiCat Well new used Rift S are going for ...  \n",
       "\n",
       "[41157 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected =  dataset.loc[:, [\"OriginalTweet\", \"clean_tweet\"]]\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.Sentiment.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\programdata\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.20.2)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (8.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2020.12.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Preferé\n",
      "[nltk_data]     Briges\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!python -m nltk.downloader stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\programdata\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (8.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.20.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.4.0)\n",
      "Requirement already satisfied: pathy in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pathy->spacy) (3.0.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: en-core-web-md==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.0.0/en_core_web_md-3.0.0-py3-none-any.whl#egg=en_core_web_md==3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from en-core-web-md==3.0.0) (3.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (20.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (8.0.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: pathy in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.11.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.20.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.50.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.24.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.15.0)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pathy->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.1.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.4)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['clean_tweet'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>document_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>MeNyrbie  Phil Gahan  Chrisitv   and   and</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Coronavirus Australia  Woolworths to give elde...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>Me  ready to go at supermarket during the  COV...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>You know it  s getting tough when  KameronWild...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>TartiiCat Well new used Rift S are going for ...</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \\\n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1      advice Talk to your neighbours family to excha...            Positive   \n",
       "2      Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3      My food stock is not the only one which is emp...            Positive   \n",
       "4      Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "...                                                  ...                 ...   \n",
       "41152  Airline pilots offering to stock supermarket s...             Neutral   \n",
       "41153  Response to complaint not provided citing COVI...  Extremely Negative   \n",
       "41154  You know itÂs getting tough when @KameronWild...            Positive   \n",
       "41155  Is it wrong that the smell of hand sanitizer i...             Neutral   \n",
       "41156  @TartiiCat Well new/used Rift S are going for ...            Negative   \n",
       "\n",
       "                                             clean_tweet  document_length  \n",
       "0           MeNyrbie  Phil Gahan  Chrisitv   and   and                 45  \n",
       "1      advice Talk to your neighbours family to excha...              237  \n",
       "2      Coronavirus Australia  Woolworths to give elde...              109  \n",
       "3      My food stock is not the only one which is emp...              284  \n",
       "4      Me  ready to go at supermarket during the  COV...              288  \n",
       "...                                                  ...              ...  \n",
       "41152  Airline pilots offering to stock supermarket s...               80  \n",
       "41153  Response to complaint not provided citing COVI...              138  \n",
       "41154  You know it  s getting tough when  KameronWild...              136  \n",
       "41155  Is it wrong that the smell of hand sanitizer i...              111  \n",
       "41156   TartiiCat Well new used Rift S are going for ...              255  \n",
       "\n",
       "[41157 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['document_length'] = dataset['clean_tweet'].apply(lambda tokens: len(tokens))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'document_leght'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'document_leght'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-de0936c5f4f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'document_leght'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'document_leght'"
     ]
    }
   ],
   "source": [
    "dataset['document_leght'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import nltk.corpus\n",
    "import numpy as np\n",
    "from nltk.text import Text\n",
    "\n",
    "freq = nltk.FreqDist(np.hstack(dataset['clean_tweet']))\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_tweet'] = dataset['clean_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression de @user\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i,'',input_txt)\n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlevons les mots courts\n",
    "dataset['clean_tweet'] = dataset['clean_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenisation\n",
    "# créer la nouvelle variable des tweet tokenisés\n",
    "tokenized_tweet = dataset['clean_tweet'].apply(lambda x: x.split())\n",
    "tokenized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Appliquer le stemmer pour tokenized_tweet\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un texte à partir de tous les tweets\n",
    "all_words = ' '.join([text for text in dataset['clean_tweet']])\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraire les caractéristiques des tweets nettoyés\n",
    "new_dataset = dataset[['clean_tweet','Sentiment']]\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrait des stopword\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset['clean_tweet'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,valid = train_test_split(new_dataset,test_size = 0.3,random_state=0,stratify = new_dataset.Sentiment.values) #stratification means that the train_test_split method returns training and test subsets that have the same proportions of class labels as the input dataset.\n",
    "print(\"train shape : \", train.shape)\n",
    "print(\"test shape : \", valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "stop = list(stopwords.words('english'))\n",
    "vectorizer = CountVectorizer(decode_error = 'replace',stop_words = stop)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train.clean_tweet.values)\n",
    "X_test = vectorizer.transform(valid.clean_tweet.values)\n",
    "\n",
    "y_train = train.Sentiment.values\n",
    "y_test = valid.Sentiment.values\n",
    "\n",
    "print(\"X_train.shape : \", X_train.shape)\n",
    "print(\"X_test.shape : \", X_test.shape)\n",
    "print(\"y_train.shape : \", y_train.shape)\n",
    "print(\"y_test.shape : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naiveByes_clf = MultinomialNB()\n",
    "\n",
    "naiveByes_clf.fit(X_train,y_train)\n",
    "\n",
    "NB_prediction = naiveByes_clf.predict(X_test)\n",
    "NB_accuracy = accuracy_score(y_test,NB_prediction)\n",
    "print(\"training accuracy Score    : \",naiveByes_clf.score(X_train,y_train))\n",
    "print(\"Validation accuracy Score : \",NB_accuracy )\n",
    "print(classification_report(NB_prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "logreg_prediction = logreg.predict(X_test)\n",
    "logreg_accuracy = accuracy_score(y_test,logreg_prediction)\n",
    "print(\"Training accuracy Score    : \",logreg.score(X_train,y_train))\n",
    "print(\"Test accuracy Score : \",logreg_accuracy )\n",
    "print(classification_report(logreg_prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "rf_clf.fit(X_train,y_train)\n",
    "\n",
    "rf_prediction = rf_clf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test,rf_prediction)\n",
    "print(\"Training accuracy Score    : \",rf_clf.score(X_train,y_train))\n",
    "print(\"Test accuracy Score : \",rf_accuracy )\n",
    "print(classification_report(rf_prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes', 'Logistic Regression', \n",
    "              'Random Forest'],\n",
    "    'Test accuracy': [NB_accuracy, logreg_accuracy, \n",
    "              rf_accuracy]})\n",
    "\n",
    "models.sort_values(by='Test accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Le meilleur modele  \n",
    "Cette partie est la reponse à la question 5 nous avons constaté que parmi les trois algorithmes utilisés; la regression logistique a la meilleure Précision; soit 61%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classe à Prédire\n",
    "CLASSES_LIST = np.unique(dataset['Sentiment'])\n",
    "n_out = len(CLASSES_LIST)\n",
    "\n",
    "print(CLASSES_LIST, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_test), annot=True, xticklabels=set(y_train), yticklabels=set(y_train))\n",
    "plt.ylabel('Vraies classses')\n",
    "plt.xlabel('Classes prédites')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(x, x**2, x, x**3)\n",
    "axes[0].set_title(\"plages d'axes par défaut\")\n",
    "\n",
    "axes[1].plot(x, x**2, x, x**3)\n",
    "axes[1].axis('tight')\n",
    "axes[1].set_title(\"axes serrés\")\n",
    "\n",
    "axes[2].plot(x, x**2, x, x**3)\n",
    "axes[2].set_ylim([0, 60])\n",
    "axes[2].set_xlim([2, 5])\n",
    "axes[2].set_title(\"gamme d'axes personnalisés\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.plot(x, y, 'r')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title('title')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "# default grid appearance\n",
    "axes[0].plot(x, x**2, x, x**3, lw=2)\n",
    "axes[0].grid(True)\n",
    "\n",
    "# custom grid appearance\n",
    "axes[1].plot(x, x**2, x, x**3, lw=2)\n",
    "axes[1].grid(color='b', alpha=0.5, linestyle='dashed', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "      \n",
    "ax.plot(x, x**2, x, np.exp(x))\n",
    "ax.set_yticks([0, 50, 100, 150])\n",
    "\n",
    "ax.set_title(\"title\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "\n",
    "fig.subplots_adjust(left=0.15, right=.9, bottom=0.1, top=0.9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(12,3))\n",
    "\n",
    "axes[0].scatter(xx, xx + 0.25*np.random.randn(len(xx)))\n",
    "axes[0].set_title(\"scatter\")\n",
    "\n",
    "axes[1].step(n, n**2, lw=2)\n",
    "axes[1].set_title(\"step\")\n",
    "\n",
    "axes[2].bar(n, n**2, align=\"center\", width=0.5, alpha=0.5)\n",
    "axes[2].set_title(\"bar\")\n",
    "\n",
    "axes[3].fill_between(x, x**2, x**3, color=\"green\", alpha=0.5);\n",
    "axes[3].set_title(\"fill_between\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
